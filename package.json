{
  "name": "prompt_injct_protect",
  "version": "1.0.0",
  "description": "browser extension system that processes all textual content encountered in AI-powered browsers to detect and flag prompt injection attacks before they are sent to a large language model (LLM). The extension must provide fine-grained filtering and give the user full control over how flagged content is handled.",
  "type": "module",
  "scripts": {
    "test": "node --test"
  }
}
