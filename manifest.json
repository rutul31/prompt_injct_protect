{
  "manifest_version": 3,
  "name": "LLM Prompt Guard",
  "version": "0.1.0",
  "description": "Detects and moderates prompt injection attempts in all text sent to LLMs.",
  "permissions": ["storage", "scripting", "activeTab"],
  "host_permissions": ["<all_urls>"],
  "action": {
    "default_title": "LLM Prompt Guard",
    "default_popup": "popup/popup.html"
  },
  "options_page": "options/options.html",
  "background": {
    "service_worker": "src/service_worker.js",
    "type": "module"
  },
  "content_scripts": [
    {
      "matches": ["<all_urls>"],
      "js": [
        "src/messaging.js",
        "src/storage.js",
        "src/util.js",
        "src/textExtraction.js",
        "src/preprocess.js",
        "src/chunker.js",
        "src/overlay.js",
        "src/sidebar.js",
        "src/integration.js",
        "src/content.js"
      ],
      "run_at": "document_idle"
    }
  ],
  "icons": {
    "16": "assets/icon16.png"
  }
}
